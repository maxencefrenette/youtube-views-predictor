{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a93a5c",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bbd9f",
   "metadata": {},
   "source": [
    "### Model: Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e158de-7319-4c77-bc4b-b3b5ced0be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../data')\n",
    "from process_data import process_data\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "#turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "IMAGE_PATH = '../data/Youtube Thumbnails/' # replace with your path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de51a207-0a76-4d84-9536-e89290e09f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train,X_test,y_test = process_data(buckets = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affefa34-1b36-4c70-b237-e09a67e5dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(IMAGE_PATH):\n",
    "    \"\"\" Generate lists of images and video ids\n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images  (np.ndarray): Images of shape (N, 120, 90, 3)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    video_ids = []\n",
    "\n",
    "    # create lists of images `images_mini` \n",
    "    for idx, img in enumerate(os.listdir(IMAGE_PATH)):\n",
    "        # read video ID from path\n",
    "        video_id = img.split('/')[0]\n",
    "        video_id = video_id.split('.')[0]\n",
    "        \n",
    "        # read image\n",
    "        img = load_img(\n",
    "            IMAGE_PATH + img\n",
    "        )\n",
    "        img = img.resize((320,180))\n",
    "        # transform image to array\n",
    "        img = img_to_array(img)\n",
    "\n",
    "        #pre process\n",
    "        img = img / 255\n",
    "        \n",
    "        # append to images\n",
    "        images.append(img)\n",
    "        \n",
    "        video_ids.append(video_id)\n",
    "\n",
    "    # stack images and trasnform to array\n",
    "    images = np.stack(images)\n",
    "    \n",
    "    return images, video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cb47eb-3019-4d19-bf75-9c244c35cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = preprocess_data(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02398f03-1152-4b32-a3bd-a539bc00c678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2324, 180, 320, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7d05c7-d4f8-464e-8b48-a9133abae358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tuple: 1859\n",
      "Test tuple: 465\n"
     ]
    }
   ],
   "source": [
    "train_tuple = ([], []) # tuple for train set\n",
    "test_tuple = ([], []) # tuple for test set\n",
    "\n",
    "for i in range(len(images[1])):\n",
    "    if images[1][i] in X_train['video_id'].to_list():\n",
    "        train_tuple[0].append(images[0][i])\n",
    "        train_tuple[1].append(images[1][i])\n",
    "    else:\n",
    "        test_tuple[0].append(images[0][i])\n",
    "        test_tuple[1].append(images[1][i])\n",
    "\n",
    "print(\"Train tuple:\", len(train_tuple[0]))\n",
    "print(\"Test tuple:\", len(test_tuple[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7809a415-01ef-4a2c-9270-e971e6d95a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_tuple[0])\n",
    "X_test = np.array(test_tuple[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5541e15e-ca6b-44f1-bfb2-e5090d4ea3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(pd.concat([y_train['views_category_10'], y_test['views_category_10']]))\n",
    "\n",
    "Y_train_cat = encoder.transform(y_train['views_category_10'])\n",
    "Y_test_cat = encoder.transform(y_test['views_category_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a17a56a-2f27-4555-aa06-be559c0c7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_classes,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01):\n",
    "  \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "  tf.keras.backend.clear_session()\n",
    "  np.random.seed(0)\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(keras.layers.Flatten())\n",
    "  i=0\n",
    "  for hidden_layer_size in hidden_layer_sizes:\n",
    "    i = i+1\n",
    "    model.add(tf.keras.layers.Dense(units=hidden_layer_size,\n",
    "                                    activation=activation,\n",
    "                                    name=\"Hidden\"+str(i)))\n",
    "  model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax', name='Output'))\n",
    "  \n",
    "  if optimizer == 'SGD':\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "  elif optimizer == 'Adam':\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  else:\n",
    "    print(\"error: invalid optimizer\")\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39f76c15-5969-4add-9796-3f8a896e1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(hidden_layer_sizes=[256,128],\n",
    "                       activation='relu',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       num_epochs=5):\n",
    "\n",
    "  # Build the model.\n",
    "  model = build_model(n_classes=10,\n",
    "                      hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation,\n",
    "                      optimizer=optimizer,\n",
    "                      learning_rate=learning_rate)\n",
    "    \n",
    "\n",
    "  # Train the model.\n",
    "  print('Training...')\n",
    "  history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train_cat,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=0)\n",
    "\n",
    "  print(model.summary())\n",
    "\n",
    "  # Retrieve the training metrics (after each train epoch) and the final test\n",
    "  # accuracy.\n",
    "  train_accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "  plt.plot(train_accuracy, label='train_accuracy')\n",
    "  plt.plot(val_accuracy, label='validation accuracy')\n",
    "  plt.xticks(range(num_epochs))\n",
    "  plt.xlabel('Train epochs')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  test_accuracy = model.evaluate(x=X_test, y=Y_test_cat, verbose=0,\n",
    "                                 return_dict=True)['accuracy']\n",
    "  predict_x=model.predict(X_test) \n",
    "  classes_x=np.argmax(predict_x,axis=1)\n",
    "  return test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ccd1a68-c129-49b1-b968-09b0802a632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 172800)            0         \n",
      "                                                                 \n",
      " Hidden1 (Dense)             (None, 256)               44237056  \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,271,242\n",
      "Trainable params: 44,271,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 28ms/step\n",
      "Test Accuracy: 0.1269\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %1.4f' %train_and_evaluate(activation='tanh',learning_rate = .0005,optimizer='SGD',num_epochs=5,hidden_layer_sizes=[256,128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7650a-0ae5-4f55-b4bc-ef51d1189c07",
   "metadata": {},
   "source": [
    "\n",
    "DATA | HIDDEN SIZES | ACTIVATION | OPTIMIZER | LEARNING RATE | EPOCHS | #PARAMETERS | TEST ACCURACY\n",
    "-|-|-|-|-|-|-|-\n",
    "thumbnails|[256,128]|tanh|SGD|0.005|10|44,271,242| 0.1097\n",
    "thumbnails|[256,128]|tanh|SGD|0.02|10|44,271,242| 0.0882\n",
    "thumbnails|[512,256,128]|tanh|SGD|0.01|10|88,639,626| 0.1097\n",
    "thumbnails|[256,256,256,128]|tanh|SGD|0.01|10|44,402,826| 0.1097\n",
    "thumbnails|[256,128]|tanh|SGD|0.01|10| 44,271,242| 0.0968\n",
    "thumbnails|[256,128]|tanh|SGD|0.01|5|44,271,242|0.107\n",
    "thumbnails|[256,128]|tanh|Adam|0.01|5|44,271,242| 0.086\n",
    "thumbnails|[256,128]|relu|Adam|0.01|5|44,271,242| 0.068\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22ad7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (320, 180)\n",
    "CONTRAST_FACTOR = 3\n",
    "DELTA = 0.3\n",
    "\n",
    "def preprocess_data_part2(X_train, y_train, X_test, y_test):\n",
    "    \"\"\" \n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    images  (np.ndarray): Images of shape (N, 320, 180, 3)\n",
    "    y (np.ndarray): Labels of shape (N,)   \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 320, 180, 3)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 320, 180, 3)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### image transformation on training, validation, and test data ###\n",
    "    ###################################################################\n",
    "    # image resize\n",
    "    X_train = tf.image.resize(X_train, size=IMAGE_SIZE)\n",
    "    X_test = tf.image.resize(X_test, size=IMAGE_SIZE)\n",
    "    \n",
    "    ### image augmentation on training data ###\n",
    "    ###########################################\n",
    "    # adjust brightness\n",
    "    X_train_augm = tf.image.adjust_brightness(X_train, delta=DELTA)\n",
    "    \n",
    "    # adjust contrast\n",
    "    X_train_augm = tf.image.adjust_contrast(X_train_augm, contrast_factor=CONTRAST_FACTOR)\n",
    "\n",
    "    # random flip\n",
    "    X_train_augm = tf.image.random_flip_left_right(X_train_augm)\n",
    "    \n",
    "    # concatenate original X_train and augmented X_train data\n",
    "    X_train = tf.concat([X_train, X_train_augm],axis=0)\n",
    "    \n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = y_train\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd6f1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (1859, 180, 320, 3)\n",
      "Y_train shape (1859,)\n",
      "X_test shape (465, 180, 320, 3)\n",
      "y_test shape (465,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"X_train shape {X_train.shape}\")\n",
    "print(f\"Y_train shape {Y_train_cat.shape}\")\n",
    "print(f\"X_test shape {X_test.shape}\")\n",
    "print(f\"y_test shape {Y_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55a58e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug, Y_train_cat_aug, X_test_aug, Y_test_cat_aug = preprocess_data_part2(X_train, Y_train_cat, X_test, Y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0032cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (3718, 320, 180, 3)\n",
      "Y_train shape (3718,)\n",
      "X_test shape (465, 320, 180, 3)\n",
      "y_test shape (465,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"X_train shape {X_train_aug.shape}\")\n",
    "print(f\"Y_train shape {Y_train_cat_aug.shape}\")\n",
    "print(f\"X_test shape {X_test_aug.shape}\")\n",
    "print(f\"y_test shape {Y_test_cat_aug.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f05b1",
   "metadata": {},
   "source": [
    "<u>The architecture of our CNN model is as follows</u>:\n",
    "\n",
    "1. the model receives input images of size 320 x 180 x 3 (the images have three color channels)\n",
    "2. the input data goes through two convolutional layers that have kernels of size 5 x 5\n",
    "3. the first convolution has 32 output feature maps, and the second one has 64\n",
    "4. each convolution layer is followed by a max-pooling layer (this will reduce the size of the feature maps)\n",
    "5. the last two layers of the model are fully connected with a droput layer in between\n",
    "\n",
    "For each convolution we use strides=(1,1) to preserve the dimension of the inputs in the resulting feature maps. For the pooling layers, we set strides=(2,2) to subsample the image and shrink the size of the output feature maps. For the dropout layer, we set the probability of dropping input units during training to 0.5.\n",
    "\n",
    "\n",
    "We will implement this architecture using TensorFlow Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea3cae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 320, 180, 16)      448       \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 106, 60, 16)       0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 106, 60, 32)       4640      \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 35, 20, 32)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 22400)             0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 1024)              22938624  \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,953,962\n",
      "Trainable params: 22,953,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# add first convolution layer to the model\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format='channels_last',\n",
    "    name='conv_1',\n",
    "    activation='relu'))\n",
    "\n",
    "\n",
    "# add a max pooling layer with pool size (2,2) and strides of 2\n",
    "# (this will reduce the spatial dimensions by half)\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(3, 3),\n",
    "    name='pool_1'))\n",
    "\n",
    "\n",
    "# add second convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    name='conv_2',\n",
    "    activation='relu'))\n",
    "\n",
    "# add second max pooling layer with pool size (2,2) and strides of 2\n",
    "# (this will further reduce the spatial dimensions by half)\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(3, 3), name='pool_2')\n",
    ")\n",
    "\n",
    "\n",
    "# add a fully connected layer (need to flatten the output of the previous layers first)\n",
    "model.add(tf.keras.layers.Flatten()) \n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1024,\n",
    "    name='fc_1', \n",
    "    activation='relu'))\n",
    "\n",
    "# add dropout layer\n",
    "model.add(tf.keras.layers.Dropout(\n",
    "    rate=0.5))\n",
    "\n",
    "# add the last fully connected layer\n",
    "# this last layer sets the activation function to \"None\" in order to output the logits \n",
    "# note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "# in TensorFlow logits are prefered for numerical stability\n",
    "# set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10,\n",
    "    activation='softmax',\n",
    "    name='Output'))\n",
    "\n",
    "\n",
    "# build model and print summary\n",
    "tf.random.set_seed(1)\n",
    "model.build(input_shape=(None, 320, 180, 3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "147a816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "              loss='sparse_categorical_crossentropy', #set from_ligits=True because our last layer does not apply sigmoid\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e7b444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 44s 366ms/step - loss: 2.3326 - accuracy: 0.1017 - val_loss: 2.3028 - val_accuracy: 0.0753\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 44s 376ms/step - loss: 2.2797 - accuracy: 0.1342 - val_loss: 2.3041 - val_accuracy: 0.1204\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 44s 376ms/step - loss: 2.2445 - accuracy: 0.1716 - val_loss: 2.3101 - val_accuracy: 0.0882\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 44s 376ms/step - loss: 2.1966 - accuracy: 0.2106 - val_loss: 2.3102 - val_accuracy: 0.0817\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 45s 381ms/step - loss: 2.1293 - accuracy: 0.2579 - val_loss: 2.3287 - val_accuracy: 0.0731\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 44s 378ms/step - loss: 2.0276 - accuracy: 0.3185 - val_loss: 2.3764 - val_accuracy: 0.0882\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 44s 379ms/step - loss: 1.8723 - accuracy: 0.3846 - val_loss: 2.4159 - val_accuracy: 0.0839\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 44s 379ms/step - loss: 1.6727 - accuracy: 0.4650 - val_loss: 2.4275 - val_accuracy: 0.1054\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 44s 378ms/step - loss: 1.4777 - accuracy: 0.5409 - val_loss: 2.7504 - val_accuracy: 0.0688\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 45s 385ms/step - loss: 1.2865 - accuracy: 0.6119 - val_loss: 2.5055 - val_accuracy: 0.1054\n"
     ]
    }
   ],
   "source": [
    "# set random seed to get reproductible results \n",
    "# neural network algorithms are stochastic (e.g., due to random weight initialization); setting a random seed helps to get more stable results after each run\n",
    "# however, best way to deal with randomness is to repeat your experiment many times (30+) and use statistics to summarize the performance of the model\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "history = model.fit(X_train_aug, Y_train_cat_aug,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_test_aug, Y_test_cat_aug)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c4b2d",
   "metadata": {},
   "source": [
    "*Written answer*:\n",
    "\n",
    "| Training accuracy | Validation accuracy |  kernel size |  strides | pool size  |  learning rate | optimizer  | brightness (delta) |  contrast factor | flip_on_train  |\n",
    "|:-:                |:-:                  |:-:           |:-:       |:-:         |:-:             |:-:         |:-:                 |:-:               |:-:             |\n",
    "| 0.9618              | 0.0968                | 5,5          | 1,1      | 3,3        | 0.001          | Adam       | 0.3                | 3                | yes            |\n",
    "| 0.9680              | 0.1097                 | <font color=\"red\">3,3</font>     | 1,1      | 3,3        | 0.001          | Adam       | 0.3                | 3                | yes            |\n",
    "| 0.8886               | 0.0882                 | 3,3          | <font color=\"red\">2,2</font>  | 3,3        | 0.001          | Adam       | 0.3                | 3                | yes            |\n",
    "| 0.9648               | 0.0946                 | 3,3          | 1,1      | 3,3   | 0.001          | Adam       | <font color=\"red\">0.1</font>                | 3                | yes            |\n",
    "| 0.9683               | 0.0839                 | 3,3          | 1,1      | 2,2        | 0.001       | Adam       | 0.3                | <font color=\"red\">2</font>                | yes            |\n",
    "| 0.6119               | 0.1054                 | 3,3          | 1,1      | 2,2        | 0.001          |<font color=\"red\">SGD</font>     | 0.3                | 3                | yes            |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4f6a24194c21ef49ca8751a1660e4b9adfcf917651b692dc64a8cd26b72dbbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
